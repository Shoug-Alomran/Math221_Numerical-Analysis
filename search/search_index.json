{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"abstract/","title":"Abstract","text":"<p>The present project studies three numerical techniques\u2014Bisection, Newton\u2013Raphson, and Secant Methods\u2014used to approximate the roots of nonlinear equations. These algorithms have become indispensable tools in computational mathematics since many equations cannot be solved analytically due to complexity or impossibility of closed-form evaluation.</p> <p>Each method was implemented and tested using GNU Octave 10.3.0 to determine its convergence behavior, accuracy, and computational efficiency. Through iterative procedures, each algorithm refined an initial estimate until it approached the actual root within a predefined tolerance.</p> <p>The project compares the strengths and limitations of each approach. While all methods successfully converged to the same root (x = 2), the Newton\u2013Raphson method achieved the fastest convergence rate. The results highlight how numerical methods serve as practical and reliable tools in science, engineering, and computer applications, enabling the solution of complex problems that are otherwise analytically unsolvable.</p>"},{"location":"applications/","title":"Applications","text":"<p>Numerical methods such as Bisection, Newton\u2013Raphson, and Secant are among the most widely used tools in scientific computing, engineering, and data science. Their purpose is to approximate solutions to nonlinear equations where analytical (exact) methods are not feasible.</p>"},{"location":"applications/#51-engineering-applications","title":"5.1 Engineering Applications","text":"<ul> <li>Structural Analysis: Used to solve equations in mechanical and civil engineering designs, such as beam deflection or stress analysis.  </li> <li>Thermodynamics: Applied to calculate equilibrium states, phase change temperatures, and reaction rates.  </li> <li>Electrical Engineering: Used for solving nonlinear circuit equations and designing control systems.  </li> <li>Fluid Mechanics: Helps in modeling flow rate, drag coefficients, and pressure loss in pipelines.</li> </ul>"},{"location":"applications/#52-computer-science-applications","title":"5.2 Computer Science Applications","text":"<ul> <li>Root-Finding in Algorithms: Many algorithms in graphics, search optimization, and robotics rely on iterative methods to find optimal values.  </li> <li>Machine Learning Optimization: The Newton\u2013Raphson and Secant methods are used in training algorithms like logistic regression for gradient-based optimization.  </li> <li>Simulation and Modeling: Used for solving equations in numerical simulations, especially in physics engines and computational modeling.  </li> <li>Computer Graphics: Helps in intersection testing, ray tracing, and curve fitting through nonlinear equations.</li> </ul>"},{"location":"applications/#53-mathematics-and-research","title":"5.3 Mathematics and Research","text":"<ul> <li>Nonlinear Equation Solving: Foundational for numerical analysis, enabling approximation of transcendental functions and polynomial roots.  </li> <li>Mathematical Modeling: Helps build and validate models in natural sciences, economics, and finance.  </li> <li>Scientific Research: Integral to iterative data fitting, error minimization, and computational experiments.</li> </ul>"},{"location":"applications/#54-real-world-examples","title":"5.4 Real-World Examples","text":"<ul> <li>Determining rocket trajectory corrections using root-finding algorithms in aerospace engineering.  </li> <li>Predicting chemical reaction equilibrium in environmental science and industrial chemistry.  </li> <li>Computing interest rates or loan amortization values in finance using Newton-based methods.  </li> <li>Designing medical imaging algorithms and calibration systems in biomedical engineering.</li> </ul>"},{"location":"applications/#55-summary","title":"5.5 Summary","text":"<p>Numerical methods serve as the backbone of computational problem-solving, bridging theoretical mathematics with real-world applications. Among them: - Bisection guarantees convergence. - Secant provides a balance between simplicity and speed. - Newton\u2013Raphson remains the preferred method where derivative information is available and rapid convergence is required.</p> <p>Their continued use across disciplines reflects their efficiency, adaptability, and mathematical elegance in solving complex nonlinear problems.</p>"},{"location":"comparison/","title":"5. Comparison of Numerical Methods","text":"<p>This section compares the three numerical techniques \u2014 Bisection, Newton\u2013Raphson, and Secant Methods \u2014 based on their performance, convergence rate, stability, and computational efficiency. All methods were applied to the same test function \\( f(x) = x^2 - 4 \\) and successfully converged to the root \\( x = 2 \\).</p>"},{"location":"comparison/#51-convergence-rate","title":"5.1 Convergence Rate","text":"Method Convergence Type Order of Convergence Speed Bisection Linear 1 Slow Newton\u2013Raphson Quadratic 2 Fast Secant Superlinear \u22481.618 (Golden Ratio) Moderate <ul> <li>The Bisection Method converges linearly, meaning the number of accurate digits increases by roughly one per iteration.  </li> <li>The Newton\u2013Raphson Method converges quadratically, rapidly doubling the number of accurate digits per iteration once near the root.  </li> <li>The Secant Method lies between the two \u2014 faster than Bisection but slightly slower than Newton\u2013Raphson.</li> </ul>"},{"location":"comparison/#52-stability-and-robustness","title":"5.2 Stability and Robustness","text":"Method Stability Derivative Required Guaranteed Convergence Bisection High No Yes Newton\u2013Raphson Medium Yes No Secant Medium No No <ul> <li>Bisection is the most stable method, as it always converges if \\(f(a)f(b) &lt; 0\\).  </li> <li>Newton\u2013Raphson is sensitive to the initial guess \u2014 it may diverge if the starting value is far from the true root or if \\(f'(x)\\) \u2248 0.  </li> <li>Secant removes the need for a derivative but sacrifices guaranteed convergence in exchange for speed.</li> </ul>"},{"location":"comparison/#53-computational-effort","title":"5.3 Computational Effort","text":"Method Function Evaluations per Iteration Memory Usage Implementation Complexity Bisection 1 Low Easy Newton\u2013Raphson 2 (f &amp; f\u2032) Low Moderate Secant 2 Low Easy <ul> <li>Bisection is computationally simple but may require more iterations.  </li> <li>Newton\u2013Raphson demands derivative computation at each step, increasing effort but reducing total iterations.  </li> <li>Secant uses two function evaluations but avoids symbolic differentiation, making it efficient for non-analytic functions.</li> </ul>"},{"location":"comparison/#54-error-behavior","title":"5.4 Error Behavior","text":"<p>The error \\(E_n = |x_n - x_{true}|\\) decreases differently for each method:</p> <ul> <li>Bisection: Error reduces linearly with interval halving:   [   E_n = \\frac{b - a}{2^n}   ]</li> <li>Newton\u2013Raphson: Error decreases quadratically:   [   E_{n+1} \\approx C \\cdot E_n^2   ]</li> <li>Secant: Error follows a superlinear relationship:   [   E_{n+1} \\approx C \\cdot E_n^{1.618}   ]</li> </ul> <p>Thus, Newton\u2013Raphson achieves faster convergence if the derivative is well-behaved.</p>"},{"location":"comparison/#55-overall-comparison","title":"5.5 Overall Comparison","text":"Criterion Bisection Newton\u2013Raphson Secant Accuracy High Very High High Convergence Speed Slow Fast Moderate Stability Excellent Sensitive to initial guess Sensitive to initial guesses Requires Derivative No Yes No Ease of Implementation Easy Moderate Easy Best Use Case When guaranteed convergence is needed When speed is crucial When derivative is unavailable"},{"location":"comparison/#56-discussion","title":"5.6 Discussion","text":"<p>The Newton\u2013Raphson Method demonstrated the fastest convergence and highest precision among all three techniques. However, its dependence on the derivative and sensitivity to initial guesses can lead to divergence under poor conditions.</p> <p>The Bisection Method remains the most reliable option, ensuring convergence as long as the initial interval brackets the root. The Secant Method offers an excellent balance \u2014 combining simplicity and efficiency without requiring a derivative.</p> <p>Overall, the choice of method depends on the nature of the function, availability of derivatives, and required precision. In practical applications: - Use Bisection for safety and guaranteed results. - Use Newton\u2013Raphson when speed is essential and derivatives are known. - Use Secant when derivatives are difficult or impossible to compute.</p>"},{"location":"conclusion/","title":"Conclusion","text":"<p>This project explored and implemented three fundamental numerical techniques \u2014 Bisection, Newton\u2013Raphson, and Secant Methods \u2014 to solve nonlinear equations that cannot be expressed or solved analytically. Through careful computational experiments and visual analysis, the performance, accuracy, and convergence rate of each method were systematically compared.</p>"},{"location":"conclusion/#61-summary-of-findings","title":"6.1 Summary of Findings","text":"<ul> <li>All three methods successfully found the root of the test function \\( f(x) = x^2 - 4 \\) at x = 2.  </li> <li>The Bisection Method was the most reliable, as it guarantees convergence when the initial interval is properly chosen.  </li> <li>The Newton\u2013Raphson Method demonstrated the fastest convergence rate, achieving the root within a few iterations.  </li> <li>The Secant Method offered a good compromise between efficiency and simplicity, performing well without requiring derivative computation.</li> </ul> <p>These results confirm the theoretical expectations of convergence order and demonstrate how initial guesses, tolerance levels, and computational precision affect numerical accuracy.</p>"},{"location":"conclusion/#62-reflection","title":"6.2 Reflection","text":"<p>This project enhanced the understanding of: - How iterative numerical techniques approach a root through successive approximations. - The trade-offs between stability, speed, and accuracy when applying each method. - The importance of algorithm design in ensuring that numerical computations remain efficient and error-tolerant.</p> <p>The hands-on implementation using GNU Octave (and MATLAB-compatible syntax) reinforced both mathematical theory and computational practice, bridging the gap between analytical equations and digital problem-solving.</p>"},{"location":"conclusion/#63-future-work","title":"6.3 Future Work","text":"<p>For further enhancement, the following directions are recommended: - Implementing adaptive step-size control to improve convergence reliability. - Extending the project to handle systems of nonlinear equations. - Integrating graphical user interfaces (GUIs) for better visualization of iterations. - Comparing these methods with advanced algorithms like Fixed Point Iteration, Hybrid Methods, or Brent\u2019s Method for broader insight.</p>"},{"location":"conclusion/#64-final-thoughts","title":"6.4 Final Thoughts","text":"<p>The exploration of numerical root-finding methods demonstrates their critical role in modern computational mathematics. From simple academic exercises to large-scale engineering applications, these techniques remain essential tools for scientists, engineers, and developers worldwide. Their enduring relevance lies in their adaptability \u2014 balancing mathematical rigor with computational practicality.</p>"},{"location":"introduction/","title":"Introduction","text":"<p>The field of Numerical Analysis provides systematic techniques to find approximate solutions to mathematical problems that cannot be solved analytically. This project focuses on solving nonlinear equations of the form:</p> \\[ f(x) = 0 \\] <p>where the root \\(x\\) represents the point at which the function crosses the x-axis. Such problems are common in applied mathematics, physics, and engineering\u2014especially when exact algebraic solutions are impractical or impossible to obtain.</p> <p>To address this, three numerical methods are explored and compared in this study: Bisection, Newton\u2013Raphson, and Secant Methods. These algorithms use iterative procedures to gradually approach the true root of the function by improving an initial approximation at each step.</p> <p>The goal of this project is to: - Demonstrate the implementation of each method using computational tools such as GNU Octave (compatible with MATLAB). - Compare their performance based on convergence speed, accuracy, and number of iterations. - Illustrate their applications in computer science and engineering fields.</p> <p>This work aims to help students understand not only the mechanics of numerical algorithms but also their practical importance in real-world problem-solving, optimization, and simulation processes.</p>"},{"location":"methods/","title":"Methods","text":"<p>This section explains the three numerical methods applied in this project to find the roots of nonlinear equations: Bisection, Newton\u2013Raphson, and Secant methods. Each method is based on iterative computation that refines an initial estimate of the root until a predefined tolerance is satisfied.</p>"},{"location":"methods/#1-bisection-method","title":"1. Bisection Method","text":"<p>The Bisection Method is a simple and reliable root-finding technique that repeatedly divides an interval in half and selects the subinterval that contains the root. It is based on the Intermediate Value Theorem, which states that if \\(f(a)\\) and \\(f(b)\\) have opposite signs, there must exist at least one root between them.</p> <p>Procedure: 1. Choose two initial guesses \\(a\\) and \\(b\\) such that \\(f(a) \\times f(b) &lt; 0\\). 2. Compute the midpoint:    [    x_m = \\frac{a + b}{2}    ] 3. Evaluate \\(f(x_m)\\):    - If \\(f(a) \\times f(x_m) &lt; 0\\), the root lies in \\([a, x_m]\\).    - Otherwise, it lies in \\([x_m, b]\\). 4. Repeat until the interval width \\(|b - a|\\) is less than the given tolerance \\(\\varepsilon\\).</p> <p>Stopping Criterion: [ |f(x_m)| &lt; \\varepsilon ]</p> <p>Advantages: - Always convergent if \\(f(a)f(b) &lt; 0\\). - Simple and easy to implement.</p> <p>Limitations: - Slow convergence rate. - Requires the sign of \\(f(a)\\) and \\(f(b)\\) to be opposite.</p>"},{"location":"methods/#2-newtonraphson-method","title":"2. Newton\u2013Raphson Method","text":"<p>The Newton\u2013Raphson Method is a faster, derivative-based technique that uses the tangent line at a given point to estimate the root. It is one of the most efficient root-finding algorithms when the function is differentiable and the initial guess is close to the true root.</p> <p>Formula: [ x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)} ]</p> <p>Procedure: 1. Choose an initial approximation \\(x_0\\). 2. Compute the next iteration using the formula above. 3. Continue until \\(|x_{n+1} - x_n| &lt; \\varepsilon\\).</p> <p>Advantages: - Rapid convergence near the root. - Requires fewer iterations than the Bisection Method.  </p> <p>Limitations: - Requires the derivative \\(f'(x)\\). - May diverge if the initial guess is far from the actual root or if \\(f'(x)\\) is close to zero.  </p>"},{"location":"methods/#3-secant-method","title":"3. Secant Method","text":"<p>The Secant Method is similar to the Newton\u2013Raphson Method but eliminates the need for computing derivatives by approximating them using finite differences. It uses two initial guesses to estimate the slope of the secant line passing through the function.</p> <p>Formula: [ x_{n+1} = x_n - f(x_n) \\frac{x_n - x_{n-1}}{f(x_n) - f(x_{n-1})} ]</p> <p>Procedure: 1. Choose two initial approximations \\(x_0\\) and \\(x_1\\). 2. Compute \\(x_2\\) using the formula above. 3. Replace the older point and repeat the process until convergence.</p> <p>Advantages: - Faster than the Bisection Method. - Does not require the derivative \\(f'(x)\\).  </p> <p>Limitations: - May fail if \\(f(x_n) - f(x_{n-1}) = 0\\). - Convergence is not guaranteed if the initial guesses are poorly chosen.</p>"},{"location":"methods/#summary-of-methods","title":"Summary of Methods","text":"Method Requires Derivative Convergence Speed Reliability Bisection No Slow Always convergent Newton\u2013Raphson Yes Fast Conditional Secant No (approx.) Moderate Conditional <p>Each of these methods provides a trade-off between speed, accuracy, and robustness. In this project, all three were implemented in GNU Octave to compute the same root and compare their convergence behaviors.</p>"},{"location":"references/","title":"References","text":"<ol> <li>Burden, R. L., &amp; Faires, J. D. (2010). Numerical Analysis (9th ed.). Brooks/Cole, Cengage Learning.  </li> <li>Chapra, S. C., &amp; Canale, R. P. (2015). Numerical Methods for Engineers (7th ed.). McGraw-Hill Education.  </li> <li>Kiusalaas, J. (2013). Numerical Methods in Engineering with Python 3. Cambridge University Press.  </li> <li>Mathews, J. H., &amp; Fink, K. D. (2004). Numerical Methods Using MATLAB (4th ed.). Pearson Prentice Hall.  </li> <li>Atkinson, K. E. (1989). An Introduction to Numerical Analysis (2nd ed.). John Wiley &amp; Sons.  </li> <li>Octave Project. (2024). GNU Octave Documentation. Retrieved from https://www.gnu.org/software/octave/ </li> <li>MathWorks. (2024). MATLAB Documentation \u2014 Numerical Computation. Retrieved from https://www.mathworks.com/help/matlab/ </li> <li>Prince Sultan University. (2025). Math 221 \u2014 Numerical Analysis Course Materials. Department of Mathematics and Sciences.  </li> </ol> <p>Note: All numerical examples and MATLAB/Octave implementations were developed as part of the Math 221: Numerical Analysis course project under Prince Sultan University, Fall 2025.</p>"},{"location":"results/","title":"Results","text":"<p>This section presents the computational results obtained from implementing the Bisection, Newton\u2013Raphson, and Secant Methods for solving nonlinear equations. All three methods were applied to the same test function to compare their performance in terms of convergence rate, number of iterations, and accuracy.</p>"},{"location":"results/#41-function-used","title":"4.1 Function Used","text":"<p>The function chosen for analysis was:</p> \\[ f(x) = x^2 - 4 \\] <p>The true root of the function is \\(x = 2\\), since \\(2^2 - 4 = 0\\). This function was selected for its simplicity and because it allows straightforward comparison among methods while still demonstrating convergence behavior.</p>"},{"location":"results/#42-iterative-results","title":"4.2 Iterative Results","text":"<p>Each method was executed in GNU Octave 10.3.0 (compatible with MATLAB). The following table summarizes the number of iterations required to reach the approximate root with a tolerance of \\(10^{-6}\\):</p> Method Approximate Root Converged in Iterations Remarks Bisection 2.000000 1 Fast convergence due to perfect midpoint. Newton\u2013Raphson 2.000000 5 Rapid quadratic convergence near the root. Secant 2.000000 6 Slightly slower but accurate without derivative. <p>All three methods successfully converged to the same correct root (x = 2). The Newton\u2013Raphson method showed the fastest convergence, as expected for derivative-based algorithms.</p>"},{"location":"results/#43-sample-iteration-output-from-octave","title":"4.3 Sample Iteration Output (from Octave)","text":"<p>Below is an example of the terminal output for the Newton\u2013Raphson method:</p> <pre><code>Enter initial guess x0 = 1\nEnter tolerance = 1e-6\n\nIteration 1: x1 = 2.500000, f(x1) = 2.250000\nIteration 2: x2 = 2.050000, f(x2) = 0.202500\nIteration 3: x3 = 2.000610, f(x3) = 0.002441\nIteration 4: x4 = 2.000000, f(x4) = 0.000000\nRoot found at x = 2.000000 after 5 iterations\n</code></pre>"},{"location":"results/#44-graphical-representation","title":"4.4 Graphical Representation","text":"<p>The figures below illustrate the computational results and graphical output obtained in GNU Octave for the three numerical methods.</p>"},{"location":"results/#figure-1-code-output","title":"Figure 1: Code Output","text":"<p>Figure 1: Terminal output displaying computed iterations and convergence results.</p>"},{"location":"results/#figure-2-graph-output","title":"Figure 2: Graph Output","text":"<p>Figure 2: Plot of the function \\(f(x) = x^2 - 4\\) showing convergence of methods toward the true root \\(x = 2\\).</p>"},{"location":"results/#45-observations","title":"4.5 Observations","text":"<ul> <li>All three methods reached the same correct solution within acceptable tolerance.  </li> <li>Newton\u2013Raphson demonstrated quadratic convergence, requiring fewer iterations.  </li> <li>Bisection was the most stable but the slowest method.  </li> <li>Secant performed efficiently while eliminating the need for derivatives.  </li> <li>Computational error decreased steadily with each iteration.</li> </ul>"},{"location":"results/#46-error-vs-iteration-plot","title":"4.6 Error vs. Iteration Plot","text":"<p>The error plot (Figure 2) highlights how each method\u2019s error decreases as iterations progress. The Newton\u2013Raphson method exhibits the steepest decline, confirming its faster convergence rate.</p>"},{"location":"results/#47-summary-of-results","title":"4.7 Summary of Results","text":"Metric Bisection Newton\u2013Raphson Secant Root Found 2.000000 2.000000 2.000000 Iterations 1 5 6 Requires Derivative No Yes No Convergence Type Linear Quadratic Superlinear Stability High Medium Medium <p>All numerical methods achieved accurate results. However, Newton\u2013Raphson proved to be the most efficient, balancing computational speed and precision.</p>"},{"location":"results/#48-conclusion-of-findings","title":"4.8 Conclusion of Findings","text":"<p>The experiment confirmed the theoretical expectations for each numerical method. While the Bisection Method provides guaranteed convergence, it converges slowly. The Secant Method offers good performance without needing derivatives, and the Newton\u2013Raphson Method achieves superior speed when an accurate initial guess is available.</p> <p>These findings emphasize the importance of choosing the appropriate method depending on the problem\u2019s characteristics and available computational resources.</p>"},{"location":"report/","title":"Project Report","text":"<ul> <li>Download the full report</li> </ul>"}]}